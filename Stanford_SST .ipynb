{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timothy Ng**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gSrVJwp3E9H"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This report summarizes my analysis of the Stanford SST Sentiment Dataset, which comprises 8741 individual sentences extracted from movie reviews. Each review is classified into either of two categories: positive or negative. By analyzing this data, we can gain insight into how language composition affects sentiment, which can be useful in various applications.\n",
    "\n",
    "One practical benefit of building predictive models on this data is that it can be used to automatically classify the sentiment of large amounts of text data, such as product reviews or social media posts. This allows for quicker and more efficient analysis of customer feedback. The insights gained from this analysis can then be used by businesses to improve their products and services, as well as their marketing strategies. In addition, the model can be used in other applications, such as chatbots or virtual assistants, to better understand and respond to users' needs and emotions.\n",
    "\n",
    "You can find the full code and model testing notebook to come here: https://github.com/timnyt/SST-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbRvd7CKNOtk"
   },
   "outputs": [],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare==0.0.189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3PiJXBhC5y-",
    "outputId": "12309f84-ddb5-4c9e-b8d7-8e6c910f9552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [=============================================>   ]\n",
      "\n",
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get competition data\n",
    "from aimodelshare import download_data\n",
    "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jT0qFCZFNzHq",
    "outputId": "2efdad4f-3cdb-4672-ccde-c08160641698"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Rock is destined to be the 21st Century 's...\n",
       "1    The gorgeously elaborate continuation of `` Th...\n",
       "2    Singer/composer Bryan Adams contributes a slew...\n",
       "3                 Yet the act is still charming here .\n",
       "4    Whether or not you 're enlightened by any of D...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up X_train, X_test, and y_train_labels objects\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
    "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
    "\n",
    "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
    "\n",
    "# ohe encode Y data\n",
    "y_train = pd.get_dummies(y_train_labels)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzPoXPj3V7u"
   },
   "source": [
    "##2.   Preprocessing\n",
    "\n",
    "For this exercise, we will be using a variety of different deep learning models including LSTMS and word embeddings using the Keras package. Many of these functions require the input text to be integer encoded. Our preprocessor, therefore, will tokenize each of the words in our corpus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQ5d2FzVifKO",
    "outputId": "ffa01b9a-0ede-47e6-c115-9e233411efbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 50)\n",
      "(1821, 50)\n"
     ]
    }
   ],
   "source": [
    "# This preprocessor function makes use of the tf.keras tokenizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Build vocabulary from training text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# preprocessor tokenizes words and makes sure all documents have the same length\n",
    "def preprocessor(data, maxlen=50, max_words=10000):\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "    return X\n",
    "\n",
    "print(preprocessor(X_train).shape)\n",
    "print(preprocessor(X_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X52kECL43b-O"
   },
   "source": [
    "##3. Modeling \n",
    "\n",
    "Much of the modelling for this competition was done in a seperate notebook. For brevity, I will present the three models which performed best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "efHwcw3Dlt2-"
   },
   "outputs": [],
   "source": [
    "#Separate validation data \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
    "     X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLRT2tV1QT3t",
    "outputId": "72c2fc96-3a86-4bf5-815e-f92665d32e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.9/dist-packages (1.3.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (2.27.1)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "! pip install keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukMNuc8ZD1a-"
   },
   "source": [
    "#Model 1: Embedding + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzMyHyQ8mEBQ",
    "outputId": "066808f1-1d17-442c-ab9e-cfb4928bc701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 06m 26s]\n",
      "val_accuracy: 0.7536126971244812\n",
      "\n",
      "Best val_accuracy So Far: 0.7731214165687561\n",
      "Total elapsed time: 00h 16m 17s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "import keras_tuner as kt\n",
    "\n",
    "#Define model structure & parameter search space with function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Embedding(10000, 16, input_length=50))\n",
    "    model.add(LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), #range 32-512 inclusive, minimum step between tested values is 32\n",
    "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"], #only postiive or negative therefore binary coressentropy\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#initialize the tuner (which will search through parameters)\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model, \n",
    "    objective=\"val_accuracy\", # objective to optimize\n",
    "    max_trials=3, #max number of trials to run during search\n",
    "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
    "    overwrite=True,\n",
    "    directory=\"tuning_model\",\n",
    "    project_name=\"tuning_units\",\n",
    ")\n",
    "\n",
    "tuner.search(preprocessor(x_train_split), y_train_split, epochs=3, validation_data=(preprocessor(x_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wUCrr3gc-8I",
    "outputId": "e2e01dd2-420e-41e8-ae26-d6e93044dec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "217/217 [==============================] - 26s 102ms/step - loss: 0.6604 - accuracy: 0.5906\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 22s 103ms/step - loss: 0.4948 - accuracy: 0.7762\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 22s 100ms/step - loss: 0.3696 - accuracy: 0.8396\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.2997 - accuracy: 0.8749\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.2583 - accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.2263 - accuracy: 0.9101\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.2056 - accuracy: 0.9159\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.1826 - accuracy: 0.9270\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 21s 98ms/step - loss: 0.1712 - accuracy: 0.9308\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 0.1532 - accuracy: 0.9382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f692a7f2190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model with best hyperparameters\n",
    "\n",
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "tuned_model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "tuned_model.fit(x=preprocessor(X_train), y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmJAnmO-5AcU"
   },
   "source": [
    "#### Save preprocessor function to local \"preprocessor.zip\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VGacc0LDaMA",
    "outputId": "33c91120-839b-4843-dc8b-fe9b20d9e583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your preprocessor is now saved to 'preprocessor.zip'\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.export_preprocessor(preprocessor,\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOWBa8Cv5LdL"
   },
   "source": [
    "#### Save model to local \".onnx\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pEhvnRiQDlY5"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(tuned_model, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"tuned_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHWkAzvX3m8O"
   },
   "source": [
    "###Generate predictions from X_test data and submit model to competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtgkM02MDpkO",
    "outputId": "5c75fbdc-d4b1-41e0-ebf7-70f864cdcc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set credentials using modelshare.org username/password\n",
    "from aimodelshare.aws import set_credentials\n",
    "    \n",
    "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this Movie Review Playground\n",
    "\n",
    "set_credentials(apiurl=apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fKNGSww8EGgi"
   },
   "outputs": [],
   "source": [
    "#Instantiate Competition\n",
    "import aimodelshare as ai\n",
    "mycompetition= ai.Competition(apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ql4wksyEUnP",
    "outputId": "c83b71b2-5c57-46b7-f981-87d0c33ba205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 13ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 385\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model: \n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "prediction_column_index=tuned_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"tuned_model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN1zvAmNEq17"
   },
   "outputs": [],
   "source": [
    "# Get leaderboard to explore current best model architectures\n",
    "\n",
    "# Get raw data in pandas data frame\n",
    "data = mycompetition.get_leaderboard()\n",
    "\n",
    "# Stylize leaderboard data\n",
    "mycompetition.stylize_leaderboard(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwNKs0wP4r5s"
   },
   "source": [
    "## Model 2: Embedding + Conv1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgSs5PAtPCZH",
    "outputId": "c5358743-c285-49d4-e5bf-4075eff3f87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 12s]\n",
      "val_accuracy: 0.7644508481025696\n",
      "\n",
      "Best val_accuracy So Far: 0.7644508481025696\n",
      "Total elapsed time: 00h 00m 12s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "\n",
    "#Define model structure & parameter search space with function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Embedding(10000, 16, input_length=50))\n",
    "    model.add(Conv1D(64,5, activation  = \"relu\"))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer= \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "#initialize the tuner (which will search through parameters)\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model, \n",
    "    objective=\"val_accuracy\", # objective to optimize\n",
    "    max_trials=3, #max number of trials to run during search\n",
    "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
    "    overwrite=True,\n",
    "    directory=\"tuning_model\",\n",
    "    project_name=\"tuning_units\",\n",
    ")\n",
    "\n",
    "tuner.search(preprocessor(x_train_split), y_train_split, epochs=3, validation_data=(preprocessor(x_val), y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPNYCbezZvjp",
    "outputId": "38a1bb2c-d653-47ad-b9ca-9a066c7f5d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.6741 - accuracy: 0.5799\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.4510 - accuracy: 0.8030\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.2456 - accuracy: 0.9055\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.1334 - accuracy: 0.9565\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.0708 - accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 3s 13ms/step - loss: 0.0378 - accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 3s 13ms/step - loss: 0.0230 - accuracy: 0.9960\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 3s 14ms/step - loss: 0.0150 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 2s 11ms/step - loss: 0.0103 - accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.0073 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6926b183a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model with best hyperparameters\n",
    "\n",
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "tuned_model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "tuned_model.fit(x=preprocessor(X_train), y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aIdmSpYVPYAw"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(tuned_model, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"tuned_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "nszPPrfwPlUk",
    "outputId": "96fc05e1-edbd-4bbe-b5c5-c0382662e9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-05910a8c5f3f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Submit Model 2 to Competition Leaderboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m mycompetition.submit_model(model_filepath = \"model2.onnx\",\n\u001b[0m\u001b[1;32m      8\u001b[0m                                  \u001b[0mpreprocessor_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"preprocessor.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                  prediction_submission=prediction_labels)\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/aimodelshare/object_oriented.py\u001b[0m in \u001b[0;36msubmit_model\u001b[0;34m(self, model_filepath, preprocessor_filepath, prediction_submission, sample_data, reproducibility_env_filepath, custom_metadata, input_dict, print_output)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0maimodelshare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubmit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m         submission = submit_model(model_filepath = model_filepath, \n\u001b[0m\u001b[1;32m   1831\u001b[0m                               \u001b[0mapiurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayground_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m                               \u001b[0mprediction_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_submission\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/aimodelshare/model.py\u001b[0m in \u001b[0;36msubmit_model\u001b[0;34m(model_filepath, apiurl, prediction_submission, preprocessor, reproducibility_env_filepath, custom_metadata, submission_type, input_dict, print_output)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_filepath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m           \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m           \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileputlistofdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfileputlistofdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model2.onnx'"
     ]
    }
   ],
   "source": [
    "#Submit Model 2: \n",
    "\n",
    "#-- Generate predicted values (a list of predicted labels \"positive\" or \"negative\") (Model 2)\n",
    "prediction_labels = tuned_model.predict(preprocessor(X_test))\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"tuned_model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbtYtXwEEHKI"
   },
   "source": [
    "## Model 3: Transfer Learning with Glove Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeJdiT1koVvf",
    "outputId": "83015e0c-ee4f-41c7-d6b0-0964af118273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-18 05:16:48--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-18 05:16:48--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-18 05:16:48--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182753 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.09MB/s    in 2m 43s  \n",
      "\n",
      "2023-04-18 05:19:32 (5.04 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
    "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5y9ohjmHoYtD",
    "outputId": "1ab1664d-ceff-4153-8f5c-bfdbfeef76be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n",
      "  inflating: glove.6B.50d.txt        \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJaruMvhoekm",
    "outputId": "ac8269f3-0381-4926-dfc3-1f394ddd153b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding data for 100 feature embedding matrix\n",
    "import os\n",
    "glove_dir = os.getcwd()\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "pei5Cz8fog5R"
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_dim = 100 # change if you use txt files using larger number of features\n",
    "max_words = 10000\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcvw32NMCvV8",
    "outputId": "266f2c9d-0acc-4eb6-881c-2b11601b1167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 50, 100)           1000000   \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Glo  (None, 100)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,003,298\n",
      "Trainable params: 3,298\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(10000, 100, weights=[embedding_matrix], input_length=50, trainable=False)\n",
    "\n",
    "# Use transfer learning with glove embeddings \n",
    "model = keras.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ep-zAnvFt1JK",
    "outputId": "15d5e66d-935e-44ef-f362-40a9e022c8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.6060 - val_loss: 0.8345 - val_accuracy: 0.3165\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6543 - val_loss: 0.9556 - val_accuracy: 0.3027\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.6004 - accuracy: 0.6718 - val_loss: 0.8387 - val_accuracy: 0.4227\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.5818 - accuracy: 0.6924 - val_loss: 0.8367 - val_accuracy: 0.4357\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.5706 - accuracy: 0.7007 - val_loss: 0.8341 - val_accuracy: 0.4617\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.5710 - accuracy: 0.7043 - val_loss: 0.6541 - val_accuracy: 0.6279\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.7068 - val_loss: 0.8134 - val_accuracy: 0.4978\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.5576 - accuracy: 0.7068 - val_loss: 0.7809 - val_accuracy: 0.5260\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7070 - val_loss: 1.0480 - val_accuracy: 0.3533\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7083 - val_loss: 0.6223 - val_accuracy: 0.6568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f691b966580>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(preprocessor(X_train), y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "HvLuIvOjHLH2"
   },
   "outputs": [],
   "source": [
    "# Save model to local ONNX file\n",
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model, framework='keras',\n",
    "                          transfer_learning=True,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMidHABfHVN7",
    "outputId": "a63dddc4-9555-46d8-b951-84260fa58934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 392\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 3: \n",
    "\n",
    "#-- Generate predicted values (a list of predicted labels \"real\" or \"fake\")\n",
    "prediction_labels = model.predict(preprocessor(X_test))\n",
    "\n",
    "# Submit Model 3 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAbBsX8aEWoA"
   },
   "source": [
    "## Model Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZR_F5e032cS"
   },
   "source": [
    "After experimenting with different model architectures, my best performing model was a tuned sequential model that included an LSTM layer and an embedding layer. This model achieved a cross-validation accuracy of 0.79, which outperformed my model with a Conv1D layer and an embedding layer that achieved an accuracy of 0.78. However, the transfer learning model had the worst performance with an accuracy of only 0.65. This could be because I didn't have enough time to tune this model properly.\n",
    "\n",
    "Interestingly, I found that models with the LSTM layer tended to perform better than those without, both in terms of cross-validation score and leaderboard ranking. During the model tuning process, I discovered that the number of epochs had the most significant impact on performance. Surprisingly, dropout didn't seem to have as much effect on performance as I initially thought, and I found that no dropout gave me the best results. Although the Keras tuner suggested otherwise regarding dropout, I didn't observe any significant improvement in performance on the leaderboard."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
